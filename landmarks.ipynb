{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_face_detection = mp.solutions.face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        return None\n",
    "\n",
    "    with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, min_detection_confidence=0.5) as face_mesh:\n",
    "        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                print(image_path)\n",
    "                return face_landmarks.landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "b'Skipping line 244970: expected 5 fields, saw 6\\n'\n"
     ]
    }
   ],
   "source": [
    "db = pd.read_csv('dataset.csv', error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = db['Path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "496026\n"
     ]
    }
   ],
   "source": [
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "244968\n"
     ]
    }
   ],
   "source": [
    "print(len(set(paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.to_csv('dataset_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/5_106633.jpg\ndata/5_212740.jpg\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-24e00b84d28c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_landmarks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlandmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-969dc3b53704>\u001b[0m in \u001b[0;36mdetect_landmarks\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mloaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dir = 'data/'\n",
    "left_eye = [33, 158, 154, 7, 246, 157, 153, 161, 173, 145, 160, 163, 144, 159, 155, 133]\n",
    "right_eye = [362, 387, 390, 382, 398, 388, 373, 384, 466, 374, 385, 263, 380, 386, 249, 381]\n",
    "lips = [62, 183, 42, 41, 38, 12, 268, 271, 272, 407, 306, 325, 319, 403, 316, 15, 86, 179, \n",
    "        89, 96, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 86, 95]\n",
    "\n",
    "with open('dataset.csv', 'a') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for image in os.listdir(data_dir):\n",
    "        \n",
    "        image_path = os.path.join(data_dir, image)\n",
    "        if image_path in paths:\n",
    "            continue\n",
    "\n",
    "        landmarks = detect_landmarks(os.path.join(data_dir, image))\n",
    "        \n",
    "        if landmarks:\n",
    "            landmarks = np.array(landmarks)\n",
    "            left_eye_map = dict()\n",
    "            for idx in left_eye:\n",
    "                landmark = landmarks[idx]\n",
    "                left_eye_map[idx] = {'x': landmark.x, 'y': landmark.y}\n",
    "\n",
    "            right_eye_map = dict()\n",
    "            for idx in right_eye:\n",
    "                landmark = landmarks[idx]\n",
    "                right_eye_map[idx] = {'x': landmark.x, 'y': landmark.y}\n",
    "\n",
    "            lips_map = dict()\n",
    "            for idx in lips:\n",
    "                landmark = landmarks[idx]\n",
    "                lips_map[idx] = {'x': landmark.x, 'y': landmark.y}\n",
    "            \n",
    "            writer.writerow([image, image.split('_')[0], right_eye_map, left_eye_map, lips_map])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "landmarks = np.array(detect_landmarks('cersei.jpg'))\n",
    "image = cv2.imread('cersei.jpg')\n",
    "\n",
    "left_eye = [33, 158, 154, 7, 246, 157, 153, 161, 173, 145, 160, 163, 144, 159, 155, 133]\n",
    "right_eye = [362, 387, 390, 382, 398, 388, 373, 384, 466, 374, 385, 263, 380, 386, 249, 381]\n",
    "lips = [62, 183, 42, 41, 38, 12, 268, 271, 272, 407, 306, 325, 319, 403, 316, 15, 86, 179, \n",
    "        89, 96, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 86, 95]\n",
    "\n",
    "for landmark in landmarks[right_eye]:\n",
    "    x_px = min(math.floor(landmark.x * image.shape[1]), image.shape[1] - 1)\n",
    "    y_px = min(math.floor(landmark.y * image.shape[0]), image.shape[0] - 1)\n",
    "\n",
    "    cv2.circle(image, (x_px, y_px), 2, (255, 0, 0), 2)\n",
    "\n",
    "for landmark in landmarks[left_eye]:\n",
    "    x_px = min(math.floor(landmark.x * image.shape[1]), image.shape[1] - 1)\n",
    "    y_px = min(math.floor(landmark.y * image.shape[0]), image.shape[0] - 1)\n",
    "\n",
    "    cv2.circle(image, (x_px, y_px), 2, (255, 0, 0), 2)\n",
    "\n",
    "for landmark in landmarks[lips]:\n",
    "    x_px = min(math.floor(landmark.x * image.shape[1]), image.shape[1] - 1)\n",
    "    y_px = min(math.floor(landmark.y * image.shape[0]), image.shape[0] - 1)\n",
    "\n",
    "    cv2.circle(image, (x_px, y_px), 2, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imwrite('difference.png', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "#from skimage.measure import compare_ssim\n",
    "imageA = cv2.imread('cersei.jpg')\n",
    "imageB = cv2.imread('annotated.png')\n",
    "imageC = (imageA - imageB) * (255, 0, 0)\n",
    "\n",
    "cv2.imwrite('difference.png', imageC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}